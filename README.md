# dotnet-local-llm-starter
Minimal .NET starter for local LLM chat with Ollama (streaming + chat history), built with Microsoft.Extensions.AI and   OllamaSharp.
